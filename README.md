# ULTRA v3.0 - Cognitive Sales Engine

**AI-Powered Sales Assistant with Dual-Path Intelligence & Real-Time Psychometric Analysis**

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![React](https://img.shields.io/badge/React-18+-61DAFB.svg)](https://reactjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-3178C6.svg)](https://www.typescriptlang.org/)

---

## ğŸ¯ Overview

ULTRA v3.0 is an advanced AI-powered sales assistant that combines **real-time conversational AI** with **deep psychological profiling** to help sales professionals engage with clients more effectively. The system uses a dual-path architecture to provide both instant responses and comprehensive behavioral analysis.

### Key Features

- **ğŸš€ Fast Path** - Sub-3-second AI responses using Google Gemini
- **ğŸ§  Slow Path** - Deep 7-module analysis using DeepSeek AI (60-90s)
- **ğŸ“Š Real-Time Psychometrics** - DISC, Big Five, Schwartz Values
- **ğŸ­ Journey Stage Tracking** - Automatic progression through sales funnel
- **ğŸ’¬ WebSocket Communication** - Live updates and analysis streaming
- **ğŸ” RAG-Enhanced** - Context-aware responses using knowledge base

---

## ğŸ—ï¸ Architecture

### Dual-Path System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLIENT MESSAGE                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚              â”‚                              â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  FAST PATH  â”‚  â”‚  RAG Search  â”‚          â”‚   SLOW PATH     â”‚
      â”‚  < 3 sec    â”‚  â”‚  (Qdrant)    â”‚          â”‚  60-90 sec      â”‚
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚              â”‚                              â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   Gemini 1.5 Flash        â”‚               â”‚ DeepSeek v3.1   â”‚
      â”‚   - Direct quote to clientâ”‚               â”‚ - M1: Client DNAâ”‚
      â”‚   - Tactical next steps   â”‚               â”‚ - M2: Indicatorsâ”‚
      â”‚   - Knowledge gaps        â”‚               â”‚ - M3: Psycho    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚ - M4: Motivationâ”‚
                  â”‚                               â”‚ - M5: Predictionâ”‚
                  â”‚                               â”‚ - M6: Playbook  â”‚
                  â”‚                               â”‚ - M7: Decision  â”‚
                  â”‚                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                                        â”‚
                  â–¼                                        â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   WebSocket   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  WebSocket Queue â”‚
          â”‚   Broadcast   â”‚                     â”‚  (if offline)    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   FRONTEND    â”‚
          â”‚   Dashboard   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7-Module Analysis (Slow Path)

1. **M1: Client DNA** - Communication style, core motivations
2. **M2: Tactical Indicators** - Purchase temperature, churn risk
3. **M3: Psychometrics** - DISC, Big Five, Schwartz Values
4. **M4: Deep Motivation** - Key insights, emotional hooks
5. **M5: Predictive Paths** - Future scenarios, timeline estimates
6. **M6: Sales Playbook** - Recommended tactics, scripts
7. **M7: Decision Dynamics** - Decision-maker profile, influencers

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Node.js 18+
- Qdrant (local or cloud)
- API Keys:
  - Google Gemini API
  - Ollama Cloud API

### Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/yourusername/ultra-v3.0.git
   cd ultra-v3.0
   ```

2. **Backend setup:**
   ```bash
   # Install Python dependencies
   pip install -r requirements.txt

   # Configure environment
   cp .env.example .env
   # Edit .env with your API keys
   ```

3. **Frontend setup:**
   ```bash
   # Install Node dependencies
   npm install
   ```

4. **Start Qdrant (optional, if running locally):**
   ```bash
   docker run -p 6333:6333 qdrant/qdrant
   ```

5. **Run the application:**
   ```bash
   # Terminal 1: Backend
   uvicorn backend.main:app --reload

   # Terminal 2: Frontend
   npm run dev
   ```

6. **Access the app:**
   - Frontend: `http://localhost:5173`
   - Backend API: `http://localhost:8000`
   - API Docs: `http://localhost:8000/docs`

---

## âš™ï¸ Configuration

### Environment Variables (`.env`)

```env
# Gemini API (Fast Path)
GEMINI_API_KEY=your_gemini_api_key_here

# Ollama Cloud (Slow Path)
OLLAMA_API_KEY=your_ollama_api_key_here
OLLAMA_BASE_URL=https://ollama.com
OLLAMA_MODEL=deepseek-v3.1:671b-cloud

# Vector Database
QDRANT_URL=http://localhost:6333

# Database
DATABASE_URL=sqlite:///ultra.db
```

### Critical Configuration Notes

âš ï¸ **Model Names:**
- Fast Path: Use `gemini-1.5-flash` or `gemini-2.0-flash-thinking-exp-01-21`
- Slow Path: Must include `-cloud` suffix for Ollama Cloud

âš ï¸ **API Quotas:**
- Gemini: ~60 requests/minute (free tier)
- Ollama DeepSeek: Check your cloud credits

---

## ğŸ“– How It Works

### User Flow

1. **User sends message** â†’ Frontend via WebSocket
2. **Fast Path activates** â†’ Immediate AI response (< 3s)
   - Searches RAG knowledge base
   - Generates contextual response via Gemini
   - Provides tactical next steps + knowledge gaps
3. **Slow Path triggers** â†’ Background analysis (60-90s)
   - Deep psychological profiling
   - 7-module comprehensive analysis
   - Auto-updates journey stage if confidence â‰¥ 75%
4. **Dashboard updates** â†’ Real-time WebSocket broadcast
   - Psychometric charts update
   - New tactical indicators appear
   - Sales playbook recommendations

### Journey Stages

```
DISCOVERY â†’ CONSIDERATION â†’ INTENT â†’ NEGOTIATION â†’ CLOSING â†’ DELIVERY
```

System automatically progresses stages based on conversation analysis and confidence scores.

---

## ğŸ› ï¸ Development

### Project Structure

```
ultra-v3.0/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI app, WebSocket endpoint
â”‚   â”œâ”€â”€ ai_core.py           # Gemini Fast Path logic
â”‚   â”œâ”€â”€ analysis_engine.py   # DeepSeek Slow Path logic
â”‚   â”œâ”€â”€ rag_engine.py        # RAG retrieval (Qdrant)
â”‚   â”œâ”€â”€ database.py          # SQLAlchemy setup
â”‚   â””â”€â”€ models.py            # Database models
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/          # React components
â”‚   â”œâ”€â”€ pages/               # Page components
â”‚   â””â”€â”€ types/               # TypeScript definitions
â”œâ”€â”€ .env                     # Environment configuration
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ package.json             # Node dependencies
```

### Running Tests

```bash
# Test Gemini API
python test_gemini.py

# Test full conversation flow
python simulate_full_conversation.py
```

### Debugging

**Check backend logs:**
```bash
# Look for these success indicators:
âœ… [AI CORE] Gemini model initialized: gemini-1.5-flash
âœ… [FAST PATH] Gemini response parsed successfully
âœ… [SLOW PATH] Analysis saved to DB and broadcasted
```

**Common issues:**
- `RAG_FALLBACK` in UI â†’ Restart uvicorn (Python cache issue)
- Slow Path never completes â†’ Check Ollama model suffix
- WebSocket disconnects â†’ Verify frontend URL matches backend

---

## ğŸ”§ Troubleshooting

### Issue: System shows `RAG_FALLBACK` instead of AI responses

**Cause:** Python bytecode cache not updating after code changes

**Fix:**
```bash
# Stop uvicorn (Ctrl+C)
rm -rf backend/__pycache__
uvicorn backend.main:app --reload
```

### Issue: Slow Path returns all 50/50 psychometric scores

**Cause:** Ollama model name missing `-cloud` suffix

**Fix:** Update `.env`:
```env
OLLAMA_MODEL=deepseek-v3.1:671b-cloud  # Add -cloud suffix
```

### Issue: Background tasks die before completion

**Cause:** Garbage collector reclaiming unreferenced async tasks

**Fix:** Ensure `main.py` stores task references:
```python
manager.active_tasks[session_id] = task
```

---

## ğŸ“Š Performance

- **Fast Path Latency:** 1.5-3 seconds
- **Slow Path Duration:** 60-90 seconds (depends on Ollama quota)
- **WebSocket Throughput:** 100+ concurrent connections
- **Database:** SQLite (suitable for < 10K sessions, upgrade to PostgreSQL for production)

---

## ğŸš¨ Critical Fixes Applied

This repository includes fixes for 6 critical failures identified in forensic audit:

1. âœ… **Gemini Model:** Changed to stable `gemini-1.5-flash`
2. âœ… **Ollama Model:** Added `-cloud` suffix
3. âœ… **GC Protection:** Task references stored in `ConnectionManager`
4. âœ… **WebSocket Queueing:** Messages persisted during disconnects
5. âœ… **Error Logging:** Silent failures replaced with tracebacks
6. âœ… **Fallback Logic:** Exceptions re-raised for proper handling

See [`CRITICAL_FIXES_SUMMARY.md`](CRITICAL_FIXES_SUMMARY.md) for full details.

---

## ğŸ“ Documentation

- [Forensic Audit Report](forensic_audit_report.md) - Technical deep-dive
- [Critical Fixes Summary](CRITICAL_FIXES_SUMMARY.md) - Quick reference
- [Deployment Walkthrough](walkthrough.md) - Step-by-step guide
- [Restart Guide](RESTART_REQUIRED.md) - Cache troubleshooting

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is proprietary. All rights reserved.

---

## ğŸ™ Acknowledgments

- **Gemini API** by Google AI
- **Ollama Cloud** for DeepSeek hosting
- **Qdrant** for vector search
- **FastAPI** framework
- **React** + **Vite** for frontend

---

## ğŸ“§ Support

For issues, questions, or feature requests, please open a GitHub issue.

---

**Built with â¤ï¸ for sales professionals who leverage AI**
